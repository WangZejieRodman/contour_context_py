"""
Contour Context Loop Closure Detection - Contour Manager
è½®å»“ç®¡ç†å™¨å®ç° - ä¿®å¤ç‰ˆæœ¬
"""

import numpy as np
import cv2
from typing import List, Tuple, Dict, Optional, Any
from dataclasses import dataclass
import os

from contour_types import (
    ContourManagerConfig, ContourViewStatConfig, ContourSimThresConfig,
    ConstellationPair, BCI, RelativePoint, RunningStatRecorder,
    RET_KEY_DIM, DIST_BIN_LAYERS, NUM_BIN_KEY_LAYER, BITS_PER_LAYER,
    gauss_pdf, clamp_angle
)
from contour_view import ContourView


class ContourManager:
    """è½®å»“ç®¡ç†å™¨ç±»"""

    def __init__(self, config: ContourManagerConfig, int_id: int):
        """
        åˆå§‹åŒ–è½®å»“ç®¡ç†å™¨

        Args:
            config: é…ç½®
            int_id: æ•´æ•°ID
        """
        self.cfg = config
        self.view_stat_cfg = ContourViewStatConfig()
        self.int_id = int_id
        self.str_id = ""

        # éªŒè¯é…ç½®
        assert config.n_col % 2 == 0
        assert config.n_row % 2 == 0
        assert len(config.lv_grads) > 0

        # åæ ‡èŒƒå›´
        self.x_min = -(config.n_row // 2) * config.reso_row
        self.x_max = -self.x_min
        self.y_min = -(config.n_col // 2) * config.reso_col
        self.y_max = -self.y_min

        # æ•°æ®å­˜å‚¨
        self.bev = None
        self.cont_views: List[List[ContourView]] = [[] for _ in range(len(config.lv_grads))]
        self.cont_perc: List[List[float]] = [[] for _ in range(len(config.lv_grads))]
        self.layer_cell_cnt: List[int] = [0] * len(config.lv_grads)
        self.layer_keys: List[List[np.ndarray]] = [[] for _ in range(len(config.lv_grads))]
        self.layer_key_bcis: List[List[BCI]] = [[] for _ in range(len(config.lv_grads))]

        # BEVåƒç´ ä¿¡æ¯
        self.bev_pixfs: List[Tuple[int, Tuple[float, float, float]]] = []
        self.max_bin_val = -float('inf')
        self.min_bin_val = float('inf')

        # åˆå§‹åŒ–BEV
        self._init_bev()

    def _init_bev(self):
        """åˆå§‹åŒ–BEVå›¾åƒ"""
        self.bev = np.full((self.cfg.n_row, self.cfg.n_col), -1000.0, dtype=np.float32)

    def hash_point_to_image(self, pt: np.ndarray) -> Tuple[int, int]:
        """
        å°†ç‚¹æ˜ å°„åˆ°å›¾åƒåæ ‡

        Args:
            pt: ç‚¹åæ ‡ [x, y, z]

        Returns:
            (row, col) æˆ– (-1, -1) å¦‚æœç‚¹åœ¨èŒƒå›´å¤–
        """
        padding = 1e-2
        x, y = pt[0], pt[1]

        # æ£€æŸ¥èŒƒå›´
        if (x < self.x_min + padding or x > self.x_max - padding or
                y < self.y_min + padding or y > self.y_max - padding or
                (y * y + x * x) < self.cfg.blind_sq):
            return -1, -1

        row = int(np.floor(x / self.cfg.reso_row)) + self.cfg.n_row // 2
        col = int(np.floor(y / self.cfg.reso_col)) + self.cfg.n_col // 2

        # éªŒè¯èŒƒå›´
        if not (0 <= row < self.cfg.n_row and 0 <= col < self.cfg.n_col):
            return -1, -1

        return row, col

    def point_to_cont_row_col(self, p_in_l: np.ndarray) -> np.ndarray:
        """
        å°†æ¿€å…‰é›·è¾¾åæ ‡ç³»ä¸­çš„ç‚¹è½¬æ¢åˆ°è¿ç»­å›¾åƒåæ ‡ç³»

        Args:
            p_in_l: æ¿€å…‰é›·è¾¾åæ ‡ç³»ä¸­çš„ç‚¹ [x, y]

        Returns:
            è¿ç»­çš„è¡Œåˆ—åæ ‡
        """
        continuous_rc = np.array([
            p_in_l[0] / self.cfg.reso_row + self.cfg.n_row / 2 - 0.5,
            p_in_l[1] / self.cfg.reso_col + self.cfg.n_col / 2 - 0.5
        ], dtype=np.float32)
        return continuous_rc

    def make_bev(self, point_cloud: np.ndarray, str_id: str = ""):
        """
        ä»ç‚¹äº‘ç”ŸæˆBEVå›¾åƒ

        Args:
            point_cloud: ç‚¹äº‘æ•°ç»„ï¼Œå½¢çŠ¶ä¸º [N, 3] æˆ– [N, 4]
            str_id: å­—ç¬¦ä¸²ID
        """
        print(f"DEBUG: make_bev() å¼€å§‹æ‰§è¡Œ for {str_id}")
        print(f"[BEV_DEBUG] {str_id}: pointcloud shape={point_cloud.shape}")
        print(f"[BEV_DEBUG] {str_id}: pointcloud hash={hash(point_cloud.tobytes())}")
        print(f"[BEV_DEBUG] {str_id}: first 3 points=\n{point_cloud[:3]}")

        assert point_cloud.shape[0] > 10, "ç‚¹äº‘æ•°é‡å¤ªå°‘"

        self.str_id = str_id if str_id else f"scan_{self.int_id}"

        # æ¸…ç©ºä¹‹å‰çš„æ•°æ®
        self.bev_pixfs.clear()
        self._init_bev()

        # ä¸ºæ¯ä¸ªæ …æ ¼ä¿å­˜å±‚çº§æ©ç ,ç”¨ä½œåé¢ç¯å½¢ç‰¹å¾ç”Ÿæˆæ—¶å€™ï¼Œè®¡ç®—æŸåƒç´ æ‰€åœ¨ä½ç½®æœ‰å¤šå°‘ä¸ªå±‚çº§å­˜åœ¨ç»“æ„ï¼Œåæ˜ è¯¥åƒç´ ä½ç½®çš„"å‚ç›´ç»“æ„ä¸°å¯Œåº¦"
        lv_grads = self.cfg.lv_grads
        num_levels = len(lv_grads) - 1  # 10ä¸ªå±‚çº§
        self.layer_masks = np.zeros((self.cfg.n_row, self.cfg.n_col, num_levels), dtype=bool)

        tmp_pillars = {}

        # å¤„ç†æ¯ä¸ªç‚¹
        for pt in point_cloud:
            row, col = self.hash_point_to_image(pt)
            if row >= 0:
                height = self.cfg.lidar_height + pt[2]

                # æ›´æ–°æœ€å¤§é«˜åº¦ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                if self.bev[row, col] < height:
                    self.bev[row, col] = height
                    # è®¡ç®—è¿ç»­åæ ‡
                    coor_f = self.point_to_cont_row_col(pt[:2])
                    hash_key = row * self.cfg.n_col + col
                    tmp_pillars[hash_key] = (coor_f[0], coor_f[1], height)

                # åˆ¤æ–­è¯¥ç‚¹å±äºå“ªä¸ªå±‚çº§å¹¶è®°å½•
                for level in range(num_levels):
                    h_min = lv_grads[level]
                    h_max = lv_grads[level + 1]
                    if h_min <= height < h_max:
                        self.layer_masks[row, col, level] = True
                        # ä¸breakï¼Œå› ä¸ºä¸€ä¸ªåƒç´ ä½ç½®å¯èƒ½æœ‰å¤šä¸ªå±‚çº§çš„ç‚¹

                # æ›´æ–°èŒƒå›´
                self.max_bin_val = max(self.max_bin_val, height)
                self.min_bin_val = min(self.min_bin_val, height)

        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        self.bev_pixfs = [(k, v) for k, v in tmp_pillars.items()]
        self.bev_pixfs.sort(key=lambda x: x[0])  # æŒ‰hashé”®æ’åº

        print(f"Max/Min bin height: {self.max_bin_val:.3f} {self.min_bin_val:.3f}")
        print(f"Continuous Pos size: {len(self.bev_pixfs)}")

        # æ–°å¢ï¼šè¾“å‡ºå±‚çº§æ©ç ç»Ÿè®¡ä¿¡æ¯
        total_pixels_with_data = np.sum(np.any(self.layer_masks, axis=2))
        layer_counts = np.sum(self.layer_masks, axis=(0, 1))
        print(f"Pixels with data: {total_pixels_with_data}")
        print(f"Points per level: {layer_counts}")
        print(f"DEBUG: make_bev() æ‰§è¡Œå®Œæˆ for {str_id}")

    def make_contours_recursive(self):
        """é€’å½’ç”Ÿæˆè½®å»“ - ä¿®æ”¹ä¸ºåŒºé—´åˆ†å‰²æ¨¡å¼"""
        print("DEBUG: make_contours_recursive() å¼€å§‹æ‰§è¡Œ")
        full_roi = (0, 0, self.cfg.n_col, self.cfg.n_row)
        mask = np.ones((1, 1), dtype=np.uint8)

        # ä¿®æ”¹ï¼šç›´æ¥å¤„ç†æ¯ä¸ªé«˜åº¦åŒºé—´ï¼Œä¸å†é€’å½’
        self._make_contours_interval_based(full_roi)
        print("DEBUG: _make_contours_interval_based() æ‰§è¡Œå®Œæˆ")

        # å¯¹æ¯å±‚çš„è½®å»“æŒ‰é¢ç§¯æ’åºå¹¶è®¡ç®—ç™¾åˆ†æ¯”
        for ll in range(len(self.cont_views)):
            self.cont_views[ll].sort(key=lambda x: x.cell_cnt, reverse=True)

            # è®¡ç®—å±‚çº§æ€»åƒç´ æ•°
            self.layer_cell_cnt[ll] = sum(cont.cell_cnt for cont in self.cont_views[ll])

            # è®¡ç®—æ¯ä¸ªè½®å»“çš„é¢ç§¯ç™¾åˆ†æ¯”
            self.cont_perc[ll] = []
            for cont in self.cont_views[ll]:
                if self.layer_cell_cnt[ll] > 0:
                    perc = cont.cell_cnt / self.layer_cell_cnt[ll]
                else:
                    perc = 0.0
                self.cont_perc[ll].append(perc)

        print("DEBUG: è½®å»“æ’åºå’Œç™¾åˆ†æ¯”è®¡ç®—å®Œæˆ")

        # ç¡®ä¿è¿™äº›å‡½æ•°åœ¨æ–¹æ³•æœ«å°¾è¢«è°ƒç”¨
        self._output_detailed_contour_statistics()
        self._make_retrieval_keys()
        # _make_retrieval_keys()ä¸­åº”è¯¥è°ƒç”¨ï¼š
        self._output_retrieval_key_statistics()
        self._output_bci_statistics()

    def _make_contours_interval_based(self, cc_roi: Tuple[int, int, int, int]):
        """
        åŸºäºåŒºé—´çš„è½®å»“æå– - ä¿®å¤ç‰ˆæœ¬

        æ­£ç¡®çš„åŒºé—´åˆ†å‰²ï¼š
        - L0: [lv_grads[0], lv_grads[1])  = [0.5, 1.0)
        - L1: [lv_grads[1], lv_grads[2])  = [1.0, 1.5)
        - L2: [lv_grads[2], lv_grads[3])  = [1.5, 2.0)
        - ...
        - L7: [lv_grads[7], lv_grads[8])  = [4.0, 4.5)
        """
        x, y, w, h = cc_roi
        bev_roi = self.bev[y:y + h, x:x + w]

        lv_grads = self.cfg.lv_grads

        # âœ… ä¿®å¤ï¼šåº”è¯¥æ˜¯ len(lv_grads) - 1 ä¸ªå±‚çº§
        num_levels = len(lv_grads) - 1  # 11ä¸ªé˜ˆå€¼ç‚¹å®šä¹‰10ä¸ªåŒºé—´

        for level in range(num_levels):
            print(f"[INTERVAL_DEBUG] Processing level {level}")

            # âœ… ä¿®å¤ï¼šæ­£ç¡®çš„åŒºé—´å®šä¹‰
            h_min = lv_grads[level]  # å½“å‰åŒºé—´çš„ä¸‹ç•Œ
            h_max = lv_grads[level + 1]  # å½“å‰åŒºé—´çš„ä¸Šç•Œ

            print(f"[INTERVAL_DEBUG] Level {level}: height range [{h_min:.2f}, {h_max:.2f})")

            # åˆ›å»ºåŒºé—´æ©ç ï¼š[h_min, h_max)
            interval_mask = ((bev_roi >= h_min) & (bev_roi < h_max)).astype(np.uint8) * 255

            print(f"[INTERVAL_DEBUG] Level {level}: {np.sum(interval_mask > 0)} pixels in interval")

            # è¿é€šç»„ä»¶åˆ†æ
            # è¾“å…¥: interval_mask - å½“å‰å±‚çº§çš„äºŒå€¼å›¾åƒï¼ˆ0æˆ–255ï¼‰
            # ç®—æ³•: OpenCVä½¿ç”¨8è¿é€šæ€§æ‰«ææ‰€æœ‰ç™½è‰²åƒç´ åŒºåŸŸ
            # è¾“å‡º: num_labels = è¿é€šåŒºåŸŸæ•° + 1ï¼ˆèƒŒæ™¯labels=0ï¼‰
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
                interval_mask, connectivity=8)

            # å¤„ç†æ¯ä¸ªè¿é€šçš„åƒç´ åŒºåŸŸ
            for n in range(1, num_labels):  # è·³è¿‡èƒŒæ™¯ï¼ˆlabels=0ï¼‰
                if stats[n, cv2.CC_STAT_AREA] < self.cfg.min_cont_cell_cnt:
                    continue

                # è·å–ç»„ä»¶çš„è¾¹ç•Œæ¡†
                comp_x, comp_y, comp_w, comp_h = stats[n, :4]

                # è½¬æ¢ä¸ºå…¨å±€åæ ‡
                global_roi = (comp_x + x, comp_y + y, comp_w, comp_h)

                # åˆ›å»ºç»„ä»¶æ©ç 
                mask_n = (labels[comp_y:comp_y + comp_h, comp_x:comp_x + comp_w] == n).astype(np.uint8)

                # åˆå§‹åŒ–ç»Ÿè®¡è®°å½•å™¨
                rec = RunningStatRecorder()
                poi_r, poi_c = -1, -1

                # éå†ç»„ä»¶å†…çš„æ¯ä¸ªåƒç´ 
                for i in range(comp_h):
                    for j in range(comp_w):
                        if mask_n[i, j]:
                            global_r = i + global_roi[1]
                            global_c = j + global_roi[0]
                            poi_r, poi_c = global_r, global_c

                            # æŸ¥æ‰¾è¿ç»­åæ ‡
                            q_hash = global_r * self.cfg.n_col + global_c
                            pixf = self._search_pixf(q_hash)
                            if pixf:
                                rec.running_stats(pixf[0], pixf[1], self.bev[global_r, global_c])

                if poi_r >= 0:
                    # åˆ›å»ºè½®å»“è§†å›¾
                    contour = ContourView(level, poi_r, poi_c)
                    contour.calc_stat_vals(rec, self.view_stat_cfg)
                    self.cont_views[level].append(contour)#è½®å»“è¢«æ·»åŠ åˆ° self.cont_views[level] åˆ—è¡¨ä¸­

            print(f"[INTERVAL_DEBUG] Level {level}: extracted {len(self.cont_views[level])} contours")

    def _search_pixf(self, q_hash: int) -> Optional[Tuple[float, float, float]]:
        """æœç´¢åƒç´ æµ®ç‚¹æ•°æ®"""
        # äºŒåˆ†æœç´¢
        left, right = 0, len(self.bev_pixfs) - 1
        while left <= right:
            mid = (left + right) // 2
            if self.bev_pixfs[mid][0] == q_hash:
                return self.bev_pixfs[mid][1]
            elif self.bev_pixfs[mid][0] < q_hash:
                left = mid + 1
            else:
                right = mid - 1
        return None

    def _make_retrieval_keys(self):
        """ç”Ÿæˆæ£€ç´¢é”®"""
        roi_radius_padded = int(np.ceil(self.cfg.roi_radius + 1))

        for ll in range(len(self.cfg.lv_grads)-1):
            accumulate_cell_cnt = 0

            for seq in range(self.cfg.piv_firsts):
                key = np.zeros(RET_KEY_DIM, dtype=np.float32)
                bci = BCI(seq, ll)

                if seq < len(self.cont_views[ll]):
                    accumulate_cell_cnt += self.cont_views[ll][seq].cell_cnt

                if (seq < len(self.cont_views[ll]) and
                        self.cont_views[ll][seq].cell_cnt >= self.cfg.min_cont_key_cnt):
                    v_cen = self.cont_views[ll][seq].pos_mean
                    r_cen, c_cen = int(v_cen[0]), int(v_cen[1])

                    # å®šä¹‰æœç´¢åŒºåŸŸ
                    r_min = max(0, r_cen - roi_radius_padded)
                    r_max = min(self.cfg.n_row - 1, r_cen + roi_radius_padded)
                    c_min = max(0, c_cen - roi_radius_padded)
                    c_max = min(self.cfg.n_col - 1, c_cen + roi_radius_padded)

                    # ç”Ÿæˆç¯å½¢ç‰¹å¾
                    key = self._generate_ring_features(v_cen, r_min, r_max, c_min, c_max,
                                                       accumulate_cell_cnt, ll, seq)  # âœ… ä¼ é€’å±‚çº§å’Œåºåˆ—

                    # ç”ŸæˆäºŒè¿›åˆ¶æ˜Ÿåº§æ ‡è¯†
                    self._generate_bci(bci, ll, seq, v_cen)

                self.layer_key_bcis[ll].append(bci) #bciï¼šé‚»å±…ï¼ˆç›¸å…³ï¼‰è½®å»“ä¿¡æ¯ï¼ŒåŒ…å«dist_bin(äºŒè¿›åˆ¶ä½ä¸²è®°å½•é‚»å±…è·ç¦»åˆ†å¸ƒ)ã€nei_pts(é‚»å±…è½®å»“çš„è¯¦ç»†ä¿¡æ¯åˆ—è¡¨)ã€nei_idx_segs(æŒ‰è·ç¦»åˆ†ç»„çš„ç´¢å¼•æ®µ)ã€piv_seq(ä¸­å¿ƒè½®å»“åºå·)ã€level(æ‰€å±å±‚çº§)ã€‚
                self.layer_keys[ll].append(key) #keyï¼šå½“å‰è½®å»“ä¿¡æ¯ï¼Œ10ç»´ç‰¹å¾ï¼š[æœ€å¤§ç‰¹å¾å€¼Ã—åƒç´ æ•°, æœ€å°ç‰¹å¾å€¼Ã—åƒç´ æ•°, ç´¯ç§¯åƒç´ æ•°å¹³æ–¹æ ¹, 10-3ä¸ªç¯å½¢åˆ†å¸ƒbins]
            print(f"ç¬¬{ll}å±‚-å…¨éƒ¨è½®å»“çš„keyå’Œbciå·²ç”Ÿæˆ")

        print(f"å…¨éƒ¨å±‚-å…¨éƒ¨è½®å»“çš„keyå’Œbciå·²ç”Ÿæˆ")
        # ===== è¾“å‡ºæ£€ç´¢é”®ç»Ÿè®¡ä¿¡æ¯ =====
        print("DEBUG: å‡†å¤‡è¾“å‡ºæ£€ç´¢é”®ç»Ÿè®¡")  # æ·»åŠ è¿™è¡Œ
        self._output_retrieval_key_statistics()
        print("DEBUG: _output_retrieval_key_statistics() æ‰§è¡Œå®Œæˆ")  # æ·»åŠ è¿™è¡Œ

        # ===== BCIç»Ÿè®¡è¾“å‡º =====
        print("DEBUG: å‡†å¤‡è¾“å‡ºBCIç»Ÿè®¡")  # æ·»åŠ è¿™è¡Œ
        self._output_bci_statistics()
        print("DEBUG: _output_bci_statistics() æ‰§è¡Œå®Œæˆ")  # æ·»åŠ è¿™è¡Œ

        # ===== è¾“å‡ºæ£€ç´¢é”®ç»Ÿè®¡ä¿¡æ¯ =====
        self._output_retrieval_key_statistics()
        # ===== BCIç»Ÿè®¡è¾“å‡º =====
        self._output_bci_statistics()

    def _generate_ring_features(self, v_cen: np.ndarray, r_min: int, r_max: int,
                                c_min: int, c_max: int, accumulate_cell_cnt: int,
                                current_level: int, current_seq: int) -> np.ndarray:
        """ç”Ÿæˆç¯å½¢ç‰¹å¾"""
        key = np.zeros(RET_KEY_DIM, dtype=np.float32)

        # ä½¿ç”¨å½“å‰å±‚çº§çš„è½®å»“
        if (current_level < len(self.cont_views) and
                current_seq < len(self.cont_views[current_level])):
            cont = self.cont_views[current_level][current_seq]

            # âœ… æ·»åŠ è¯¦ç»†è°ƒè¯•è¾“å‡º
            print(f"[KEY_DEBUG] {self.str_id} L{current_level}S{current_seq}: "
                  f"eig_vals=[{cont.eig_vals[0]:.6f}, {cont.eig_vals[1]:.6f}], "
                  f"cell_cnt={cont.cell_cnt}")

            key[0] = np.sqrt(cont.eig_vals[1] * cont.cell_cnt)  # æœ€å¤§ç‰¹å¾å€¼ * è®¡æ•°
            key[1] = np.sqrt(cont.eig_vals[0] * cont.cell_cnt)  # æœ€å°ç‰¹å¾å€¼ * è®¡æ•°

            print(f"[KEY_DEBUG] {self.str_id} L{current_level}S{current_seq}: "
                  f"key[0]={key[0]:.6f}, key[1]={key[1]:.6f}")

        key[2] = np.sqrt(accumulate_cell_cnt)

        # ç¯å½¢åˆ†å¸ƒç‰¹å¾
        num_bins = RET_KEY_DIM - 3
        bin_len = self.cfg.roi_radius / num_bins
        ring_bins = np.zeros(num_bins)

        div_per_bin = 5
        discrete_divs = np.zeros(num_bins * div_per_bin)
        div_len = self.cfg.roi_radius / (num_bins * div_per_bin)
        cnt_point = 0

        # éå†ROIåŒºåŸŸæ‰€æœ‰åƒç´ 
        for rr in range(r_min, r_max + 1):
            for cc in range(c_min, c_max + 1):
                # æ£€æŸ¥æ˜¯å¦åœ¨æœç´¢åŠå¾„å†…
                q_hash = rr * self.cfg.n_col + cc
                pixf = self._search_pixf(q_hash)
                if not pixf:
                    continue

                pos = np.array([pixf[0], pixf[1]])
                dist = np.linalg.norm(pos - v_cen)

                if dist < self.cfg.roi_radius - 1e-2:
                    # è®¡ç®—è¯¥ä½ç½®æœ‰å¤šå°‘ä¸ªå±‚çº§å­˜åœ¨ç»“æ„
                    higher_cnt = np.sum(self.layer_masks[rr, cc, :])

                    # å¦‚æœè¯¥ä½ç½®æœ‰ä»»ä½•å±‚çº§çš„ç»“æ„æ‰å‚ä¸è®¡ç®—
                    if higher_cnt > 0:
                        cnt_point += 1

                        # ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒåˆ†é…åˆ°bins
                        for div_idx in range(num_bins * div_per_bin):
                            center = div_idx * div_len + 0.5 * div_len
                            discrete_divs[div_idx] += higher_cnt * gauss_pdf(center, dist, 1.0)

        # åˆå¹¶bins
        for b in range(num_bins):
            for d in range(div_per_bin):
                ring_bins[b] += discrete_divs[b * div_per_bin + d]
            if cnt_point > 0:
                ring_bins[b] *= bin_len / np.sqrt(cnt_point)

        # å¡«å……é”®çš„ç¯å½¢éƒ¨åˆ†
        key[3:3 + num_bins] = ring_bins

        print(f"[KEY_DEBUG] {self.str_id} L{current_level}S{current_seq}: "
              f"final_key[0]={key[0]:.6f}")

        return key

    def _generate_bci(self, bci: BCI, ll: int, seq: int, v_cen: np.ndarray):
        """ç”ŸæˆäºŒè¿›åˆ¶æ˜Ÿåº§æ ‡è¯†"""
        for bl in range(NUM_BIN_KEY_LAYER):  # éå†ä¸åŒçš„è·ç¦»å±‚çº§
            bit_offset = bl * BITS_PER_LAYER  # æ¯å±‚20ä¸ªbits
            layer_idx = DIST_BIN_LAYERS[bl]  # å¯¹åº”çš„é«˜åº¦å±‚çº§

            # æ·»åŠ è¾¹ç•Œæ£€æŸ¥
            if layer_idx >= len(self.cont_views):
                print(f"Warning: layer_idx {layer_idx} >= len(cont_views) {len(self.cont_views)}")
                continue

            for j in range(min(self.cfg.dist_firsts, len(self.cont_views[layer_idx]))):
                if ll != layer_idx or j != seq:# æ’é™¤è‡ªèº«è½®å»“ï¼Œåœ¨åŒå±‚ä¸åŒè½®å»“å’Œä¸åŒå±‚ä¸åŒè½®å»“é‡Œç­›é€‰
                    # è®¡ç®—ç›¸å¯¹ä½ç½®
                    vec_cc = self.cont_views[layer_idx][j].pos_mean - v_cen
                    tmp_dist = np.linalg.norm(vec_cc)

                    # è·ç¦»èŒƒå›´æ£€æŸ¥
                    min_dist = 1.0
                    max_dist = (BITS_PER_LAYER - 1) * 1.0 + min_dist

                    if tmp_dist <= min_dist or tmp_dist > max_dist - 1e-3:
                        continue

                    tmp_orie = np.arctan2(vec_cc[1], vec_cc[0])
                    dist_idx = min(int(np.floor((tmp_dist - min_dist) / 1.01)), BITS_PER_LAYER - 1)
                    dist_idx += bit_offset

                    if dist_idx < BITS_PER_LAYER * NUM_BIN_KEY_LAYER:
                        bci.dist_bin[dist_idx] = True
                        bci.nei_pts.append(RelativePoint(layer_idx, j, dist_idx, tmp_dist, tmp_orie))

        # æ’åºå¹¶å»ºç«‹ç´¢å¼•æ®µ
        if bci.nei_pts:
            bci.nei_pts.sort(key=lambda p: p.bit_pos)

            bci.nei_idx_segs = [0]
            for p1 in range(len(bci.nei_pts)):
                if bci.nei_pts[bci.nei_idx_segs[-1]].bit_pos != bci.nei_pts[p1].bit_pos:
                    bci.nei_idx_segs.append(p1)
            bci.nei_idx_segs.append(len(bci.nei_pts))

        print(f"ç¬¬{ll}å±‚-ç¬¬{seq}ä¸ªè½®å»“çš„bciå·²ç”Ÿæˆ")

    # Getteræ–¹æ³•
    def get_lev_retrieval_key(self, level: int) -> List[np.ndarray]:
        """è·å–æŒ‡å®šå±‚çº§çš„æ£€ç´¢é”®"""
        return self.layer_keys[level]

    def get_retrieval_key(self, level: int, seq: int) -> np.ndarray:
        """è·å–æŒ‡å®šå±‚çº§å’Œåºåˆ—çš„æ£€ç´¢é”®"""
        return self.layer_keys[level][seq]

    def get_lev_contours(self, level: int) -> List[ContourView]:
        """è·å–æŒ‡å®šå±‚çº§çš„è½®å»“"""
        return self.cont_views[level]

    def get_lev_total_pix(self, level: int) -> int:
        """è·å–æŒ‡å®šå±‚çº§çš„æ€»åƒç´ æ•°"""
        return self.layer_cell_cnt[level]

    def get_lev_bci(self, level: int) -> List[BCI]:
        """è·å–æŒ‡å®šå±‚çº§çš„BCI"""
        return self.layer_key_bcis[level]

    def get_bci(self, level: int, seq: int) -> BCI:
        """è·å–æŒ‡å®šå±‚çº§å’Œåºåˆ—çš„BCI"""
        return self.layer_key_bcis[level][seq]

    def get_str_id(self) -> str:
        """è·å–å­—ç¬¦ä¸²ID"""
        return self.str_id

    def get_int_id(self) -> int:
        """è·å–æ•´æ•°ID"""
        return self.int_id

    def get_config(self) -> ContourManagerConfig:
        """è·å–é…ç½®"""
        return self.cfg

    def get_area_perc(self, level: int, seq: int) -> float:
        """è·å–é¢ç§¯ç™¾åˆ†æ¯”"""
        return self.cont_perc[level][seq]

    def get_bev_image(self) -> np.ndarray:
        """è·å–BEVå›¾åƒ"""
        return self.bev.copy()

    def get_contour_image(self, level: int) -> np.ndarray:
        """è·å–æŒ‡å®šå±‚çº§çš„è½®å»“å›¾åƒ - ä¿®å¤åŒºé—´æ¨¡å¼"""
        if self.bev is None:
            return np.zeros((self.cfg.n_row, self.cfg.n_col), dtype=np.uint8)

        lv_grads = self.cfg.lv_grads

        # âœ… ä¿®å¤ï¼šä½¿ç”¨ä¸è½®å»“æå–å®Œå…¨ç›¸åŒçš„åŒºé—´å®šä¹‰
        if level < len(lv_grads) - 1:
            h_min = lv_grads[level]  # L3: 1.5
            h_max = lv_grads[level + 1]  # L3: 2.0
            # åˆ›å»ºåŒºé—´æ©ç ï¼š[h_min, h_max)
            mask = ((self.bev >= h_min) & (self.bev < h_max)).astype(np.uint8) * 255
        else:
            # æœ€åä¸€å±‚ï¼š[lv_grads[level], +âˆ)
            h_min = lv_grads[level]
            mask = (self.bev >= h_min).astype(np.uint8) * 255

        return mask

    def clear_image(self):
        """æ¸…ç†å›¾åƒä»¥èŠ‚çœå†…å­˜"""
        self.bev = None

    def resume_image(self):
        """ä»åƒç´ æ•°æ®æ¢å¤å›¾åƒ"""
        self._init_bev()
        for hash_key, (row_f, col_f, elev) in self.bev_pixfs:
            rr = hash_key // self.cfg.n_col
            cc = hash_key % self.cfg.n_col
            if rr < self.cfg.n_row and cc < self.cfg.n_col:
                self.bev[rr, cc] = elev

    @staticmethod
    def check_constell_corresp_sim(src: 'ContourManager', tgt: 'ContourManager',
                                   cstl_in: List[ConstellationPair],
                                   lb: 'ScorePairwiseSim',
                                   cont_sim: ContourSimThresConfig) -> Tuple[
        'ScorePairwiseSim', List[ConstellationPair], List[float]]:
        """
        æ£€æŸ¥æ˜Ÿåº§å¯¹åº”ç›¸ä¼¼æ€§

        Args:
            src: æºè½®å»“ç®¡ç†å™¨
            tgt: ç›®æ ‡è½®å»“ç®¡ç†å™¨
            cstl_in: è¾“å…¥æ˜Ÿåº§å¯¹åˆ—è¡¨
            lb: ä¸‹ç•Œé˜ˆå€¼
            cont_sim: è½®å»“ç›¸ä¼¼æ€§é…ç½®

        Returns:
            (åˆ†æ•°, è¿‡æ»¤åçš„æ˜Ÿåº§å¯¹, é¢ç§¯ç™¾åˆ†æ¯”)
        """
        from contour_types import ScorePairwiseSim

        ret = ScorePairwiseSim()
        cstl_out = []
        area_perc = []

        # æ£€æŸ¥ä¸ªä½“ç›¸ä¼¼æ€§
        for pr in cstl_in:
            if ContourView.check_sim(src.cont_views[pr.level][pr.seq_src],
                                     tgt.cont_views[pr.level][pr.seq_tgt], cont_sim):
                cstl_out.append(pr)

        ret.i_indiv_sim = len(cstl_out)
        if ret.i_indiv_sim < lb.i_indiv_sim:
            return ret, cstl_out, area_perc

        # æ£€æŸ¥æ–¹å‘ä¸€è‡´æ€§
        if len(cstl_out) > 1:
            # è®¡ç®—ä¸»è½´æ–¹å‘
            shaft_src = np.array([0.0, 0.0])
            shaft_tgt = np.array([0.0, 0.0])
            max_norm = 0.0

            for i in range(1, min(len(cstl_out), 10)):
                for j in range(i):
                    curr_shaft_src = (src.cont_views[cstl_out[i].level][cstl_out[i].seq_src].pos_mean -
                                      src.cont_views[cstl_out[j].level][cstl_out[j].seq_src].pos_mean)
                    curr_norm = np.linalg.norm(curr_shaft_src)

                    if curr_norm > max_norm:
                        max_norm = curr_norm
                        shaft_src = curr_shaft_src / curr_norm
                        shaft_tgt = ((tgt.cont_views[cstl_out[i].level][cstl_out[i].seq_tgt].pos_mean -
                                      tgt.cont_views[cstl_out[j].level][cstl_out[j].seq_tgt].pos_mean) / curr_norm)

            # è¿‡æ»¤æ–¹å‘ä¸ä¸€è‡´çš„å¯¹
            num_sim = len(cstl_out)
            i = 0
            while i < num_sim:
                sc1 = src.cont_views[cstl_out[i].level][cstl_out[i].seq_src]
                tc1 = tgt.cont_views[cstl_out[i].level][cstl_out[i].seq_tgt]

                if sc1.ecc_feat and tc1.ecc_feat:
                    theta_s = np.arccos(np.clip(np.dot(shaft_src, sc1.eig_vecs[:, 1]), -1, 1))
                    theta_t = np.arccos(np.clip(np.dot(shaft_tgt, tc1.eig_vecs[:, 1]), -1, 1))

                    from contour_types import diff_delt
                    if (diff_delt(theta_s, theta_t, np.pi / 6) and
                            diff_delt(np.pi - theta_s, theta_t, np.pi / 6)):
                        # ç§»é™¤æ­¤å¯¹
                        cstl_out[i], cstl_out[num_sim - 1] = cstl_out[num_sim - 1], cstl_out[i]
                        num_sim -= 1
                        continue
                i += 1

            cstl_out = cstl_out[:num_sim]

        ret.i_orie_sim = len(cstl_out)
        if ret.i_orie_sim < lb.i_orie_sim:
            return ret, cstl_out, area_perc

        # è®¡ç®—é¢ç§¯ç™¾åˆ†æ¯”
        for pair in cstl_out:
            perc = 0.5 * (src.cont_perc[pair.level][pair.seq_src] +
                          tgt.cont_perc[pair.level][pair.seq_tgt])
            area_perc.append(perc)

        return ret, cstl_out, area_perc

    @staticmethod
    def get_tf_from_constell(src: 'ContourManager', tgt: 'ContourManager',
                             cstl_pairs: List[ConstellationPair]) -> np.ndarray:
        """
        ä»æ˜Ÿåº§è®¡ç®—å˜æ¢çŸ©é˜µ

        Args:
            src: æºè½®å»“ç®¡ç†å™¨
            tgt: ç›®æ ‡è½®å»“ç®¡ç†å™¨
            cstl_pairs: æ˜Ÿåº§å¯¹åˆ—è¡¨

        Returns:
            2DåŒæ„å˜æ¢çŸ©é˜µ (3x3)
        """
        num_elem = len(cstl_pairs)
        if num_elem < 3:
            print(f"è­¦å‘Šï¼šå¯¹åº”ç‚¹ä¸è¶³({num_elem}ä¸ª)ï¼Œè¿”å›å•ä½å˜æ¢")
            return np.eye(3)

        # æ”¶é›†å¯¹åº”ç‚¹
        pointset1 = np.zeros((2, num_elem))  # src
        pointset2 = np.zeros((2, num_elem))  # tgt

        for i, pair in enumerate(cstl_pairs):
            pointset1[:, i] = src.cont_views[pair.level][pair.seq_src].pos_mean
            pointset2[:, i] = tgt.cont_views[pair.level][pair.seq_tgt].pos_mean

        # ä½¿ç”¨Umeyamaç®—æ³•è®¡ç®—å˜æ¢
        T_delta = umeyama_2d(pointset1, pointset2)

        return T_delta

    def _output_detailed_contour_statistics(self):
        """è¾“å‡ºè¯¦ç»†çš„è½®å»“ç»Ÿè®¡ä¿¡æ¯åˆ°æ—¥å¿—"""
        print("DEBUG: _output_detailed_contour_statistics() å‡½æ•°å¼€å§‹")
        try:
            contour_sizes = []
            eccentricities = []
            eigenvalue_ratios = []
            significant_ecc_count = 0
            significant_com_count = 0
            heights = []

            # æ”¶é›†æ‰€æœ‰è½®å»“çš„ç»Ÿè®¡ä¿¡æ¯
            for level in range(len(self.cont_views)):
                for contour in self.cont_views[level]:
                    # è½®å»“å°ºå¯¸
                    contour_sizes.append(contour.cell_cnt)

                    # åå¿ƒç‡
                    eccentricities.append(contour.eccen)

                    # ç‰¹å¾å€¼æ¯”ä¾‹
                    if len(contour.eig_vals) == 2 and contour.eig_vals[1] > 0:
                        ratio = contour.eig_vals[0] / contour.eig_vals[1]
                        eigenvalue_ratios.append(ratio)

                    # æ˜¾è‘—ç‰¹å¾è®¡æ•°
                    if contour.ecc_feat:
                        significant_ecc_count += 1
                    if contour.com_feat:
                        significant_com_count += 1

                    # é«˜åº¦ä¿¡æ¯
                    heights.append(contour.vol3_mean)

            # è¾“å‡ºåˆ°æ—¥å¿—
            if contour_sizes:
                # åŸºæœ¬ç»Ÿè®¡
                total_contours = len(contour_sizes)
                min_size = min(contour_sizes)
                max_size = max(contour_sizes)
                avg_size = sum(contour_sizes) / total_contours
                import statistics
                std_size = statistics.stdev(contour_sizes) if total_contours > 1 else 0

                # åŒæ—¶è¾“å‡ºåˆ°printå’Œlogging
                stats_msg = f"CONTOUR_STATS_BASIC: total={total_contours}, min={min_size}, max={max_size}, avg={avg_size:.1f}, std={std_size:.1f}"
                print(stats_msg)
                import logging
                logging.info(stats_msg)

                # å°ºå¯¸åˆ†å¸ƒç»Ÿè®¡
                size_bins = [
                    (1, 5, "æå°è½®å»“"),
                    (6, 15, "å°è½®å»“"),
                    (16, 50, "ä¸­å°è½®å»“"),
                    (51, 150, "ä¸­ç­‰è½®å»“"),
                    (151, 500, "å¤§è½®å»“"),
                    (501, float('inf'), "è¶…å¤§è½®å»“")
                ]

                for min_size, max_size, label in size_bins:
                    if max_size == float('inf'):
                        count = sum(1 for s in contour_sizes if s >= min_size)
                    else:
                        count = sum(1 for s in contour_sizes if min_size <= s <= max_size)
                    ratio = count / total_contours if total_contours > 0 else 0

                    size_dist_msg = f"CONTOUR_SIZE_DIST: {label}={count}({ratio:.3f})"
                    print(size_dist_msg)
                    logging.info(size_dist_msg)

                # å‡ ä½•ç‰¹å¾ç»Ÿè®¡
                if eccentricities:
                    avg_ecc = sum(eccentricities) / len(eccentricities)
                    std_ecc = statistics.stdev(eccentricities) if len(eccentricities) > 1 else 0

                    geom_msg = f"CONTOUR_GEOMETRY: avg_eccentricity={avg_ecc:.3f}, std_eccentricity={std_ecc:.3f}"
                    print(geom_msg)
                    logging.info(geom_msg)

                    # åå¿ƒç‡åˆ†å¸ƒ
                    ecc_bins = [
                        (0.0, 0.3, "è¿‘åœ†å½¢"),
                        (0.3, 0.6, "æ¤­åœ†å½¢"),
                        (0.6, 0.8, "é•¿æ¤­åœ†"),
                        (0.8, 1.0, "æé•¿æ¤­åœ†")
                    ]

                    for min_ecc, max_ecc, label in ecc_bins:
                        count = sum(1 for e in eccentricities if min_ecc <= e < max_ecc)
                        ratio = count / len(eccentricities)

                        ecc_dist_msg = f"CONTOUR_ECC_DIST: {label}={count}({ratio:.3f})"
                        print(ecc_dist_msg)
                        logging.info(ecc_dist_msg)

                # ç‰¹å¾å€¼æ¯”ä¾‹
                if eigenvalue_ratios:
                    avg_ratio = sum(eigenvalue_ratios) / len(eigenvalue_ratios)
                    eigval_msg = f"CONTOUR_EIGENVALUE: avg_ratio={avg_ratio:.3f}"
                    print(eigval_msg)
                    logging.info(eigval_msg)

                # æ˜¾è‘—ç‰¹å¾ç»Ÿè®¡
                if total_contours > 0:
                    ecc_feat_ratio = significant_ecc_count / total_contours
                    com_feat_ratio = significant_com_count / total_contours

                    feat_msg = f"CONTOUR_SIGNIFICANT_FEATURES: ecc_count={significant_ecc_count}({ecc_feat_ratio:.3f}), com_count={significant_com_count}({com_feat_ratio:.3f})"
                    print(feat_msg)
                    logging.info(feat_msg)

                # é«˜åº¦ç»Ÿè®¡
                if heights:
                    avg_height = sum(heights) / len(heights)
                    height_msg = f"CONTOUR_HEIGHT: avg_height={avg_height:.2f}"
                    print(height_msg)
                    logging.info(height_msg)

            print("DEBUG: _output_detailed_contour_statistics() å‡½æ•°æ­£å¸¸ç»“æŸ")

        except Exception as e:
            error_msg = f"è½®å»“ç»Ÿè®¡è¾“å‡ºå¤±è´¥: {e}"
            print(error_msg)
            import logging
            logging.error(error_msg)

    def _output_retrieval_key_statistics(self):
        """è¾“å‡ºæ£€ç´¢é”®ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯åˆ°æ—¥å¿—"""
        print("DEBUG: _output_retrieval_key_statistics() å‡½æ•°å¼€å§‹")
        try:
            key_stats = {'dim0': [], 'dim1': [], 'dim2': [], 'zero_keys': 0}
            ring_activations = []
            total_keys = 0

            # æ”¶é›†æ‰€æœ‰å±‚çº§çš„æ£€ç´¢é”®ä¿¡æ¯
            for ll in range(len(self.layer_keys)):
                for key in self.layer_keys[ll]:
                    total_keys += 1

                    if len(key) >= 3:
                        key_stats['dim0'].append(float(key[0]))
                        key_stats['dim1'].append(float(key[1]))
                        key_stats['dim2'].append(float(key[2]))

                        # æ£€æŸ¥æ˜¯å¦ä¸ºé›¶å‘é‡
                        if np.sum(key) == 0:
                            key_stats['zero_keys'] += 1

                        # æ”¶é›†ç¯å½¢ç‰¹å¾
                        if len(key) > 3:
                            ring_features = key[3:]
                            ring_activations.extend([float(x) for x in ring_features if x > 0])

            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            import logging

            # åŸºæœ¬ç»´åº¦ç»Ÿè®¡
            if key_stats['dim0']:
                import statistics

                avg_dim0 = statistics.mean(key_stats['dim0'])
                avg_dim1 = statistics.mean(key_stats['dim1'])
                avg_dim2 = statistics.mean(key_stats['dim2'])

                dim_msg = f"KEY_DIMENSIONS: dim0_avg={avg_dim0:.4f}, dim1_avg={avg_dim1:.4f}, dim2_avg={avg_dim2:.4f}"
                print(dim_msg)
                logging.info(dim_msg)

                # ç»´åº¦åˆ†å¸ƒç»Ÿè®¡
                if key_stats['dim0']:
                    min_dim0, max_dim0 = min(key_stats['dim0']), max(key_stats['dim0'])
                    std_dim0 = statistics.stdev(key_stats['dim0']) if len(key_stats['dim0']) > 1 else 0

                    dim0_dist_msg = f"KEY_DIM0_DIST: min={min_dim0:.4f}, max={max_dim0:.4f}, std={std_dim0:.4f}"
                    print(dim0_dist_msg)
                    logging.info(dim0_dist_msg)

                if key_stats['dim1']:
                    min_dim1, max_dim1 = min(key_stats['dim1']), max(key_stats['dim1'])
                    std_dim1 = statistics.stdev(key_stats['dim1']) if len(key_stats['dim1']) > 1 else 0

                    dim1_dist_msg = f"KEY_DIM1_DIST: min={min_dim1:.4f}, max={max_dim1:.4f}, std={std_dim1:.4f}"
                    print(dim1_dist_msg)
                    logging.info(dim1_dist_msg)

                if key_stats['dim2']:
                    min_dim2, max_dim2 = min(key_stats['dim2']), max(key_stats['dim2'])
                    std_dim2 = statistics.stdev(key_stats['dim2']) if len(key_stats['dim2']) > 1 else 0

                    dim2_dist_msg = f"KEY_DIM2_DIST: min={min_dim2:.4f}, max={max_dim2:.4f}, std={std_dim2:.4f}"
                    print(dim2_dist_msg)
                    logging.info(dim2_dist_msg)

            # ç¨€ç–æ€§ç»Ÿè®¡
            if total_keys > 0:
                sparsity = key_stats['zero_keys'] / total_keys
                valid_keys = total_keys - key_stats['zero_keys']

                sparse_msg = f"KEY_SPARSITY: total_keys={total_keys}, zero_keys={key_stats['zero_keys']}, sparsity={sparsity:.4f}, valid_keys={valid_keys}"
                print(sparse_msg)
                logging.info(sparse_msg)

            # ç¯å½¢ç‰¹å¾ç»Ÿè®¡
            if ring_activations:
                import statistics
                avg_activation = statistics.mean(ring_activations)
                std_activation = statistics.stdev(ring_activations) if len(ring_activations) > 1 else 0
                max_activation = max(ring_activations)

                ring_msg = f"KEY_RING_FEATURES: avg_activation={avg_activation:.4f}, std_activation={std_activation:.4f}, max_activation={max_activation:.4f}, active_count={len(ring_activations)}"
                print(ring_msg)
                logging.info(ring_msg)
            else:
                ring_msg = f"KEY_RING_FEATURES: avg_activation=0.0000, std_activation=0.0000, max_activation=0.0000, active_count=0"
                print(ring_msg)
                logging.info(ring_msg)

            # æ€»ä½“è´¨é‡è¯„ä¼°
            if total_keys > 0:
                quality_score = (1.0 - sparsity) * 0.5
                if ring_activations:
                    quality_score += min(0.5, len(ring_activations) / (total_keys * 7) * 0.5)  # å‡è®¾æ¯ä¸ªkeyæœ‰7ä¸ªring features

                quality_msg = f"KEY_QUALITY: quality_score={quality_score:.4f}"
                print(quality_msg)
                logging.info(quality_msg)

            print("DEBUG: _output_retrieval_key_statistics() å‡½æ•°æ­£å¸¸ç»“æŸ")

        except Exception as e:
            error_msg = f"æ£€ç´¢é”®ç»Ÿè®¡è¾“å‡ºå¤±è´¥: {e}"
            print(error_msg)
            import logging
            logging.error(error_msg)

    def _output_bci_statistics(self):
        """è¾“å‡ºBCIç‰¹å¾ç»Ÿè®¡ä¿¡æ¯åˆ°æ—¥å¿—"""
        print("DEBUG: _output_bci_statistics() å‡½æ•°å¼€å§‹")
        try:
            bci_neighbors = []
            neighbor_distances = []
            neighbor_angles = []
            cross_layer_connections = 0
            total_connections = 0
            distance_bits_activated = 0
            total_distance_bits = 0
            layer_connectivity = {}  # è®°å½•æ¯å±‚çš„è¿æ¥ç»Ÿè®¡

            # æ”¶é›†æ‰€æœ‰BCIçš„ä¿¡æ¯
            for ll in range(len(self.layer_key_bcis)):
                layer_connections = 0
                layer_cross_connections = 0

                for bci in self.layer_key_bcis[ll]:
                    # é‚»å±…æ•°é‡
                    neighbor_count = len(bci.nei_pts)
                    bci_neighbors.append(neighbor_count)
                    layer_connections += neighbor_count

                    # è·ç¦»ä½ç»Ÿè®¡
                    total_distance_bits += len(bci.dist_bin)
                    distance_bits_activated += np.sum(bci.dist_bin)

                    # é‚»å±…ç‚¹è¯¦ç»†ä¿¡æ¯
                    for nei_pt in bci.nei_pts:
                        neighbor_distances.append(float(nei_pt.r))
                        neighbor_angles.append(float(nei_pt.theta))
                        total_connections += 1

                        # è·¨å±‚è¿æ¥ç»Ÿè®¡
                        if nei_pt.level != ll:
                            cross_layer_connections += 1
                            layer_cross_connections += 1

                # è®°å½•æ¯å±‚çš„è¿æ¥ä¿¡æ¯
                layer_connectivity[ll] = {
                    'total_connections': layer_connections,
                    'cross_layer_connections': layer_cross_connections,
                    'bcis_count': len(self.layer_key_bcis[ll])
                }

            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            import logging
            import statistics

            # åŸºæœ¬BCIç»Ÿè®¡
            total_bcis = len([bci for bcis in self.layer_key_bcis for bci in bcis])

            if bci_neighbors:
                avg_neighbors = statistics.mean(bci_neighbors)
                std_neighbors = statistics.stdev(bci_neighbors) if len(bci_neighbors) > 1 else 0
                min_neighbors = min(bci_neighbors)
                max_neighbors = max(bci_neighbors)

                bci_basic_msg = f"BCI_BASIC_STATS: total_bcis={total_bcis}, avg_neighbors={avg_neighbors:.1f}, std_neighbors={std_neighbors:.1f}, min_neighbors={min_neighbors}, max_neighbors={max_neighbors}"
                print(bci_basic_msg)
                logging.info(bci_basic_msg)

                # é‚»å±…æ•°åˆ†å¸ƒ
                neighbor_distribution = {
                    '0_neighbors': sum(1 for n in bci_neighbors if n == 0),
                    '1-3_neighbors': sum(1 for n in bci_neighbors if 1 <= n <= 3),
                    '4-6_neighbors': sum(1 for n in bci_neighbors if 4 <= n <= 6),
                    '7-10_neighbors': sum(1 for n in bci_neighbors if 7 <= n <= 10),
                    '10+_neighbors': sum(1 for n in bci_neighbors if n > 10)
                }

                for range_name, count in neighbor_distribution.items():
                    ratio = count / total_bcis if total_bcis > 0 else 0
                    neighbor_dist_msg = f"BCI_NEIGHBOR_DIST: {range_name}={count}({ratio:.3f})"
                    print(neighbor_dist_msg)
                    logging.info(neighbor_dist_msg)

            # è·ç¦»ç»Ÿè®¡
            if neighbor_distances:
                avg_distance = statistics.mean(neighbor_distances)
                std_distance = statistics.stdev(neighbor_distances) if len(neighbor_distances) > 1 else 0
                min_distance = min(neighbor_distances)
                max_distance = max(neighbor_distances)

                distance_msg = f"BCI_DISTANCES: avg_distance={avg_distance:.2f}, std_distance={std_distance:.2f}, min_distance={min_distance:.2f}, max_distance={max_distance:.2f}"
                print(distance_msg)
                logging.info(distance_msg)

            # è§’åº¦å¤šæ ·æ€§ç»Ÿè®¡
            if neighbor_angles:
                # è§’åº¦åˆ†å¸ƒç»Ÿè®¡ (å°†è§’åº¦è½¬æ¢åˆ°0-2Ï€èŒƒå›´)
                normalized_angles = [(angle + 2 * np.pi) % (2 * np.pi) for angle in neighbor_angles]
                angle_diversity = statistics.stdev(normalized_angles) if len(normalized_angles) > 1 else 0

                # è§’åº¦åˆ†å¸ƒå‡åŒ€æ€§ (ç†æƒ³æƒ…å†µä¸‹åº”è¯¥å‡åŒ€åˆ†å¸ƒåœ¨0-2Ï€)
                angle_bins = [0] * 8  # 8ä¸ª45åº¦çš„æ‰‡åŒº
                for angle in normalized_angles:
                    bin_idx = int(angle / (np.pi / 4)) % 8
                    angle_bins[bin_idx] += 1

                angle_uniformity = 1.0 - (max(angle_bins) - min(angle_bins)) / len(
                    normalized_angles) if normalized_angles else 0

                angle_msg = f"BCI_ANGLES: angle_diversity={angle_diversity:.3f}, angle_uniformity={angle_uniformity:.3f}"
                print(angle_msg)
                logging.info(angle_msg)

            # è·¨å±‚è¿æ¥ç»Ÿè®¡
            if total_connections > 0:
                cross_layer_ratio = cross_layer_connections / total_connections
                intra_layer_connections = total_connections - cross_layer_connections

                cross_layer_msg = f"BCI_CROSS_LAYER: cross_layer_connections={cross_layer_connections}, intra_layer_connections={intra_layer_connections}, cross_layer_ratio={cross_layer_ratio:.3f}"
                print(cross_layer_msg)
                logging.info(cross_layer_msg)

            # è·ç¦»ä½æ¿€æ´»ç»Ÿè®¡
            if total_distance_bits > 0:
                activation_rate = distance_bits_activated / total_distance_bits

                bit_msg = f"BCI_DISTANCE_BITS: total_bits={total_distance_bits}, activated_bits={distance_bits_activated}, activation_rate={activation_rate:.4f}"
                print(bit_msg)
                logging.info(bit_msg)

            # æ¯å±‚è¿æ¥ç»Ÿè®¡
            for layer, stats in layer_connectivity.items():
                if stats['bcis_count'] > 0:
                    avg_conn_per_layer = stats['total_connections'] / stats['bcis_count']
                    cross_ratio_per_layer = stats['cross_layer_connections'] / max(1, stats['total_connections'])

                    layer_msg = f"BCI_LAYER_{layer}: bcis={stats['bcis_count']}, avg_connections={avg_conn_per_layer:.1f}, cross_layer_ratio={cross_ratio_per_layer:.3f}"
                    print(layer_msg)
                    logging.info(layer_msg)

            # æ˜Ÿåº§å¤æ‚åº¦è®¡ç®—
            constellation_complexity = 0.0
            if bci_neighbors and neighbor_angles:
                avg_neighbors = statistics.mean(bci_neighbors)
                angle_diversity = statistics.stdev(normalized_angles) if len(normalized_angles) > 1 else 0
                constellation_complexity = avg_neighbors * angle_diversity / 10.0  # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´

            complexity_msg = f"BCI_CONSTELLATION_COMPLEXITY: complexity_score={constellation_complexity:.3f}"
            print(complexity_msg)
            logging.info(complexity_msg)

            # è¿æ¥è´¨é‡è¯„ä¼°
            connection_quality = 0.0
            if total_bcis > 0 and bci_neighbors:
                # ç†æƒ³çš„é‚»å±…æ•°æ˜¯3-8ä¸ª
                ideal_neighbor_count = sum(1 for n in bci_neighbors if 3 <= n <= 8)
                connection_quality = ideal_neighbor_count / total_bcis

            quality_msg = f"BCI_CONNECTION_QUALITY: quality_score={connection_quality:.3f}, ideal_bcis_ratio={connection_quality:.3f}"
            print(quality_msg)
            logging.info(quality_msg)

            print("DEBUG: _output_bci_statistics() å‡½æ•°æ­£å¸¸ç»“æŸ")

        except Exception as e:
            error_msg = f"BCIç»Ÿè®¡è¾“å‡ºå¤±è´¥: {e}"
            print(error_msg)
            import logging
            logging.error(error_msg)


def umeyama_2d(src_points: np.ndarray, dst_points: np.ndarray) -> np.ndarray:
    """
    2D Umeyamaç®—æ³•è®¡ç®—ç›¸ä¼¼å˜æ¢
    """
    assert src_points.shape == dst_points.shape
    assert src_points.shape[0] == 2

    n = src_points.shape[1]
    if n < 2:
        return np.eye(3)  # ğŸ”§ å¤„ç†è¾¹ç•Œæƒ…å†µ

    # è®¡ç®—è´¨å¿ƒ
    mu_src = np.mean(src_points, axis=1, keepdims=True)
    mu_dst = np.mean(dst_points, axis=1, keepdims=True)

    # ä¸­å¿ƒåŒ–
    src_centered = src_points - mu_src
    dst_centered = dst_points - mu_dst

    # è®¡ç®—åæ–¹å·®çŸ©é˜µ
    C = src_centered @ dst_centered.T / n

    # SVDåˆ†è§£
    U, S, Vt = np.linalg.svd(C)

    # è®¡ç®—æ—‹è½¬çŸ©é˜µ
    R = Vt.T @ U.T

    # ç¡®ä¿æ˜¯æ—‹è½¬çŸ©é˜µï¼ˆè¡Œåˆ—å¼ä¸ºæ­£ï¼‰
    if np.linalg.det(R) < 0:
        Vt[-1, :] *= -1
        R = Vt.T @ U.T

    # ğŸ”§ æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
    if np.abs(np.linalg.det(R) - 1.0) > 1e-6:
        print(f"Warning: Rotation matrix determinant = {np.linalg.det(R)}")

    # è®¡ç®—å¹³ç§»
    t = mu_dst - R @ mu_src

    # æ„é€ é½æ¬¡å˜æ¢çŸ©é˜µ
    T = np.eye(3)
    T[:2, :2] = R
    T[:2, 2:3] = t

    return T
